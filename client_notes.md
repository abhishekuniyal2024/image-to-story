Date: 2-SEPT-2025
Client: UK Client

Project: Using LLMs and Vision Models to Create Picture Books for Visually Impaired Children

Client's Goal:
The client wants to use AI to generate rich, emotionally-driven descriptions of images from picture books. These descriptions need to be seamlessly integrated with the existing story text to create an engaging experience for children who cannot see. The primary aim is to make the descriptions feel like a natural part of the narrative, not just a separate add-on.

Key Conversation Points:
The client provided examples showing that simple descriptions from models like BLIP are not sufficient.
More advanced models like GPT-4.5 provide detailed descriptions but don't automatically fit into the story's context.
The core problem is figuring out how to blend the image description with the story's narrative and tone.
The client is open to using any tool that gets the job done well. The focus is on the quality of the final, integrated story.

Proposed Solution & Technical Approach:
The current two-step process (describe, then manually insert) is clunky. A more effective, two-stage AI-driven approach would be:

Stage 1: Detailed Image Description
Use a high-quality Vision-Language Model (VLM) like GPT-4o or LLaVA to generate a very detailed, raw description of the image. The more descriptive the initial output, the better.

Stage 2: Contextual Narrative Integration
Feed the detailed image description from Stage 1 into a powerful Large Language Model (LLM) like GPT-4 or LLaMA 3.
Also, provide the original story text from the book page.
Instruct the LLM to act as a creative narrator for a children's book. The prompt would ask it to rewrite or expand the story text by weaving the visual details naturally into the narrative flow. This will make the final output feel like a cohesive, single story.

Project Milestones and Timeline:
Week 1: Environment Setup & Initial Experiments
.Go through sample books, images, and examples in detail to fully understand the requirements.
.Set up tools and models for caption generation.
.Run first caption tests and expand them with ChatGPT for descriptive and emotional output.
.Deliverable: Stable environment + first batch of enriched captions.

Week 2: Story Integration
.Blend image descriptions with story text so they feel natural.
.Experiment with different prompts to ensure the AI considers story context.
.Refine strategies for smoother integration across examples.
.Deliverable: Draft version of integrated story + image descriptions.

Week 3: Workflow Automation
.Build a semi-automated workflow to process (image + text) input and return enriched outputs.
.Ensure compatibility across multiple page formats.
.Streamline iteration speed for testing multiple books.
.Deliverable: Working semi-automated pipeline.

Week 4: Refinement, Consistency & Audio Option
.Polish descriptions for emotional depth and consistency in tone.
.Validate outputs across different types of books (childrenâ€™s, fiction, etc.).
.Create internal benchmarks for quality and coherence.

.Add optional audio output feature:
.Default to US English voice for simplicity.
.Allow users to enable audio per page if desired.
.Keep framework flexible for adding regional accents (e.g., Indian English) later.
.Deliverable: Refined, consistent outputs + evaluation benchmarks + optional audio feature.

Week 5: Documentation & Final Delivery
.Test the full process end-to-end on multiple books.
.Prepare clear documentation for usage and workflow steps.
.Finalize ready-to-use system with examples and best practices.
.Deliverable: Complete, documented workflow + final polished outputs.